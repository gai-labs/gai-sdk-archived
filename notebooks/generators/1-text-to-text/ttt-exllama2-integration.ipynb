{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gai/Gen: Text-to-Text Generation using Gai with ExLlama\n",
    "\n",
    "This is useful for running LLM on CPU with consumer grade graphics card."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "\n",
    "1. Create a conda environment called `TTT`, if not already created, and install the dependencies:\n",
    "\n",
    "    ```bash\n",
    "    sudo apt update -y && sudo apt install ffmpeg git git-lfs -y\n",
    "    conda create -n TTT2 python=3.10.10 -y\n",
    "    conda activate TTT2\n",
    "    cd ../../gai-gen\n",
    "    pip install -e \".[TTT2]\"\n",
    "    ```\n",
    "\n",
    "2. Download Mistral 7B 4-Bit Quantized model into `~/gai/models` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "huggingface-cli download turboderp/Llama-3-8B-Instruct-exl2 \\\n",
    "    --revision 97d15f8fb9808afd51d7bccc3c3204ef3714f65a \\\n",
    "    --local-dir ~/gai/models/Llama-3-8B-Instruct-exl2 \\\n",
    "    --local-dir-use-symlinks False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "huggingface-cli download bartowski/Mistral-7B-Instruct-v0.3-exl2 \\\n",
    "    --revision 1a09a351a5fb5a356102bfca2d26507cdab11111 \\\n",
    "    --local-dir ~/gai/models/Mistral-7B-Instruct-v0.3-exl2 \\\n",
    "    --local-dir-use-symlinks False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Chat Completion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 23:21:11 INFO gai.gen.Gaigen:\u001b[32mGaigen: Loading generator llama3-exllama2...\u001b[0m\n",
      "2024-06-08 23:21:11 INFO gai.gen.ttt.TTT:\u001b[32mUsing engine ExLlamaV2_TTT...\u001b[0m\n",
      "2024-06-08 23:21:11 INFO gai.gen.ttt.TTT:\u001b[32mLoading model from models/Meta-Llama-3-8B-Instruct-EXL2\u001b[0m\n",
      "2024-06-08 23:21:11 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.load: Loading model from /home/roylai/gai/models/Meta-Llama-3-8B-Instruct-EXL2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-326f0d90-c6af-4dfe-ac55-3bc76ab24196', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As the last rays of sunlight faded from the sky, a lone figure emerged from the dense forest, her eyes fixed on the crumbling mansion looming before her. The wind whispered secrets in her ear, and she felt an inexplicable pull towards the ancient structure, as if the very stones held a tale waiting to be unearthed. With each step, the creaking of the wooden floorboards beneath her feet seemed to echo through the stillness, like a gentle summons to explore the mysteries within. And yet, as she pushed open the creaking door, a faint light flickered to life, illuminating the dusty halls, revealing the secrets of the forgotten mansion, and beckoning her deeper into its depths.', role='assistant', function_call=None, tool_calls=None))], created=1717860093, model='llama3-exllama2', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=144, prompt_tokens=44, total_tokens=188))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gai.gen import Gaigen\n",
    "gen = Gaigen.GetInstance(\"../../../gai-gen/gai.json\").load('llama3-exllama2')\n",
    "response = gen.create(messages=[\n",
    "    {'role':'system','content':'You are a helpful assistant that can generate short stories. You can generate a short story based on a prompt.'},\n",
    "    {'role':'user','content':'Tell me a one paragraph short story.'},\n",
    "    {'role':'assistant','content':''}], max_tokens=1000,stream=False)\n",
    "gen.unload()\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 23:20:20 INFO gai.gen.Gaigen:\u001b[32mGaigen: Loading generator mistral7b-exllama2...\u001b[0m\n",
      "2024-06-08 23:20:20 INFO gai.gen.ttt.TTT:\u001b[32mUsing engine ExLlamaV2_TTT...\u001b[0m\n",
      "2024-06-08 23:20:20 INFO gai.gen.ttt.TTT:\u001b[32mLoading model from models/Mistral-7B-Instruct-v0.3-exl2\u001b[0m\n",
      "2024-06-08 23:20:21 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.load: Loading model from /home/roylai/gai/models/Mistral-7B-Instruct-v0.3-exl2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-d017a330-6793-48ef-b901-3e2145779b8d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In the quiet town of Meadowbrook, a peculiar little store called The Curiosity Shop was nestled between quaint houses. The shop, with its old wooden sign and cobweb-covered windows, was known for its mysterious allure. One day, a young girl named Lily wandered in, her eyes wide with curiosity. As she explored the shop, she stumbled upon a small, antique music box. When she opened it, a beautiful melody filled the quiet room, and the world outside seemed to pause. As the melody ended, a golden key appeared within the box. The key was said to unlock the door to an enchanted garden, but only the one who truly loved the music could find it. Lily closed her eyes, listened to the melody once more, and felt a warm, golden light fill the room. When she opened her eyes, the key was in her hand. With a heart full of hope, she followed the key's glowing trail, ready to discover the enchanted garden.\", role='assistant', function_call=None, tool_calls=None))], created=1717860038, model='mistral7b-exllama2', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=215, prompt_tokens=42, total_tokens=257))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gai.gen import Gaigen\n",
    "gen = Gaigen.GetInstance(\"../../../gai-gen/gai.json\").load('mistral7b-exllama2')\n",
    "response = gen.create(messages=[\n",
    "    {'role':'system','content':'You are a helpful assistant that can generate short stories. You can generate a short story based on a prompt.'},\n",
    "    {'role':'user','content':'Tell me a one paragraph short story.'},\n",
    "    {'role':'assistant','content':''}], max_tokens=1000,stream=False)\n",
    "gen.unload()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 23:19:47 INFO gai.gen.Gaigen:\u001b[32mGaigen: Loading generator llama3-exllama2...\u001b[0m\n",
      "2024-06-08 23:19:47 INFO gai.gen.ttt.TTT:\u001b[32mUsing engine ExLlamaV2_TTT...\u001b[0m\n",
      "2024-06-08 23:19:47 INFO gai.gen.ttt.TTT:\u001b[32mLoading model from models/Meta-Llama-3-8B-Instruct-EXL2\u001b[0m\n",
      "2024-06-08 23:19:47 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.load: Loading model from /home/roylai/gai/models/Meta-Llama-3-8B-Instruct-EXL2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the last rays of sunlight faded from the small town of Willow Creek, a lone figure emerged from the shadows. It was Emily, a young woman with a mop of curly brown hair and a smile that could light up the darkest of rooms. She had returned to her hometown after years away, seeking solace in the familiar streets and sounds of her childhood. But as she walked down Main Street, the once-familiar buildings now seemed to loom over her like giants, their windows like empty eyes staring back. Emily quickened her pace, her heart pounding in her chest, until she reached the old oak tree where she had carved her initials with her high school sweetheart all those years ago. As she touched the scars, a warm breeze rustled the leaves, and for a moment, she felt the weight of her past lift, like the first whispered promise of a new beginning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gai.gen.Gaigen.Gaigen at 0x7f7d3ce1d540>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gai.gen import Gaigen\n",
    "gen = Gaigen.GetInstance(\"../../../gai-gen/gai.json\").load('llama3-exllama2')\n",
    "response = gen.create(messages=[\n",
    "    {'role':'user','content':'Tell me a one paragraph short story.'},\n",
    "    {'role':'assistant','content':''}\n",
    "    ], max_tokens=1000,stream=True)\n",
    "for chunk in response:\n",
    "    chunk=chunk.choices[0].delta.content\n",
    "    if chunk:\n",
    "        print(chunk, end='', flush=True)    \n",
    "print()\n",
    "gen.unload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roylai/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-08 23:17:59 INFO gai.gen.Gaigen:\u001b[32mGaigen: Loading generator mistral7b-exllama2...\u001b[0m\n",
      "2024-06-08 23:17:59 INFO gai.gen.ttt.TTT:\u001b[32mUsing engine ExLlamaV2_TTT...\u001b[0m\n",
      "2024-06-08 23:17:59 INFO gai.gen.ttt.TTT:\u001b[32mLoading model from models/Mistral-7B-Instruct-v0.3-exl2\u001b[0m\n",
      "2024-06-08 23:17:59 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.load: Loading model from /home/roylai/gai/models/Mistral-7B-Instruct-v0.3-exl2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a small coastal town, a young fisherman named Juan discovered a mysterious, glowing stone while mending his net. Overwhelmed by the peculiar artifact, he sought help from the wise old lighthouse keeper, who revealed it was the legendary Sea Stone, said to summon the mighty sea serpent Leviathan. Fearing the unknown power, Juan embarked on a journey to find the ancient seer who could guide him, hoping to harness the stone's power to protect his beloved town and sea creatures.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gai.gen.Gaigen.Gaigen at 0x7f7d3ce1d540>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gai.gen import Gaigen\n",
    "gen = Gaigen.GetInstance(\"../../../gai-gen/gai.json\").load('mistral7b-exllama2')\n",
    "response = gen.create(messages=[\n",
    "    {'role':'user','content':'Tell me a one paragraph short story.'},\n",
    "    {'role':'assistant','content':''}\n",
    "    ], max_tokens=1000,stream=True)\n",
    "for chunk in response:\n",
    "    chunk=chunk.choices[0].delta.content\n",
    "    if chunk:\n",
    "        print(chunk, end='', flush=True)\n",
    "print()\n",
    "gen.unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## JSON Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmformatenforcer import JsonSchemaParser\n",
    "from pydantic import BaseModel\n",
    "from gai.gen import Gaigen\n",
    "gen = Gaigen.GetInstance(\"../../../gai-gen/gai.json\").load('mistral7b-exllama2')\n",
    "\n",
    "# Define Schema\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    author: str\n",
    "    published_year: int\n",
    "\n",
    "text = \"\"\"Foundation is a science fiction novel by American writer\n",
    "Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
    "expanded into the Foundation series). Foundation is a cycle of five\n",
    "interrelated short stories, first published as a single book by Gnome Press\n",
    "in 1951. Collectively they tell the early story of the Foundation,\n",
    "an institute founded by psychohistorian Hari Seldon to preserve the best\n",
    "of galactic civilization after the collapse of the Galactic Empire.\n",
    "\"\"\"\n",
    "\n",
    "response = gen.create(messages=[{'role':'USER','content':text},{'role':'ASSISTANT','content':''}], schema=Book.schema(), max_tokens=1000,stream=False)\n",
    "print(response)\n",
    "gen.unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.gen import Gaigen\n",
    "gen = Gaigen.GetInstance(\"../../../gai-gen/gai.json\").load('mistral7b-exllama2')\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"google\",\n",
    "            \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "from gai.common.notebook import highlight\n",
    "\n",
    "highlight(\"Model decided to use tool: \")\n",
    "user_prompt = \"What time is it in Singapore right now?\"\n",
    "response = gen.create(\n",
    "    messages=[\n",
    "        {'role':'user','content':user_prompt},\n",
    "        {'role':'assistant','content':''}],\n",
    "    tools=tools,\n",
    "    stream=False,\n",
    "    max_new_tokens=200)\n",
    "print(response)\n",
    "\n",
    "highlight(\"Model decided not to use tool: \")\n",
    "user_prompt = \"Tell me a one paragraph story.\"\n",
    "response = gen.create(\n",
    "    messages=[\n",
    "        {'role':'user','content':user_prompt},\n",
    "        {'role':'assistant','content':''}],\n",
    "    tools=tools,\n",
    "    stream=False,\n",
    "    max_new_tokens=200)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TTT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
