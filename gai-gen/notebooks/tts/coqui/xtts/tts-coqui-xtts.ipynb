{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tested on the following libraries:\n",
    "    -   NVidia GeForce RTX 2060 6GB\n",
    "    -   Windows 11 + WSL2\n",
    "    -   Ubuntu 22.04\n",
    "    -   Python 3.10\n",
    "    -   CUDA Toolkit 11.8\n",
    "    -   openai 1.6.1\n",
    "    -   TTS 0.22.0\n",
    "    -   deepspeed 0.12.6\n",
    "\n",
    "2. Create and run the following script `xtts_download.py` to download the model:\n",
    "\n",
    "```python\n",
    "# xtts_download.py\n",
    "import os\n",
    "os.environ[\"COQUI_TOS_AGREED\"]=\"1\"\n",
    "\n",
    "from TTS.utils.manage import ModelManager\n",
    "print(\"Downloading...\")\n",
    "mm =  ModelManager(output_prefix=\"~/gai/models/tts\")\n",
    "model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "mm.download_model(model_name)\n",
    "print(\"Downloaded\")\n",
    "```\n",
    "\n",
    "Take note that loading the model for the first time will take a while for deepspeed to compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 00:09:52 INFO gai.gen.tts.XTTS_TTS:\u001b[32mXTTS generating...\u001b[0m\n",
      "2024-06-13 00:09:52 INFO gai.gen.tts.XTTS_TTS:\u001b[32mLoading XTTS...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading XTTS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roylai/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-13 00:10:14,668] [INFO] [real_accelerator.py:161:get_accelerator] \u001b[32mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "[2024-06-13 00:10:15,190] [INFO] [logging.py:96:log_dist] \u001b[32m[Rank -1] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown\u001b[0m\n",
      "[2024-06-13 00:10:15,193] [WARNING] [config_utils.py:69:_process_deprecated_field] \u001b[33mConfig parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\u001b[0m\n",
      "[2024-06-13 00:10:15,194] [WARNING] [config_utils.py:69:_process_deprecated_field] \u001b[33mConfig parameter mp_size is deprecated use tensor_parallel.tp_size instead\u001b[0m\n",
      "[2024-06-13 00:10:15,195] [INFO] [logging.py:96:log_dist] \u001b[32m[Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/roylai/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/roylai/.cache/torch_extensions/py310_cu121/transformer_inference/build.ninja...\n",
      "Building extension module transformer_inference...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load transformer_inference op: 0.062483787536621094 seconds\n",
      "[2024-06-13 00:10:15,942] [INFO] [logging.py:96:log_dist] \u001b[32m[Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module transformer_inference...\n",
      "2024-06-13 00:10:17 INFO gai.gen.tts.XTTS_TTS:\u001b[32mXTTS Loaded.\u001b[0m\n",
      "2024-06-13 00:10:17 INFO gai.gen.tts.XTTS_TTS:\u001b[32mXTTS completed.\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m response \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     12\u001b[0m   voice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVjollca Johnnie\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m   \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe definition of insanity is doing the same thing over and over and expecting different results.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m   language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m   stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[0;32m---> 18\u001b[0m \u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/TTS/lib/python3.10/site-packages/IPython/lib/display.py:130\u001b[0m, in \u001b[0;36mAudio.__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/TTS/lib/python3.10/site-packages/IPython/lib/display.py:152\u001b[0m, in \u001b[0;36mAudio._make_wav\u001b[0;34m(data, rate, normalize)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwave\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     scaled, nchan \u001b[38;5;241m=\u001b[39m \u001b[43mAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_normalize_with_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     scaled, nchan \u001b[38;5;241m=\u001b[39m Audio\u001b[38;5;241m.\u001b[39m_validate_and_normalize_without_numpy(data, normalize)\n",
      "File \u001b[0;32m~/miniconda/envs/TTS/lib/python3.10/site-packages/IPython/lib/display.py:172\u001b[0m, in \u001b[0;36mAudio._validate_and_normalize_with_numpy\u001b[0;34m(data, normalize)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_and_normalize_with_numpy\u001b[39m(data, normalize) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    174\u001b[0m         nchan \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'generator'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## XTTS_TTS\n",
    "from gai.gen.tts.XTTS_TTS import XTTS_TTS\n",
    "config={\n",
    "            \"model_name\": \"tts-coqui-xtts\",\n",
    "            \"type\": \"tts\",\n",
    "            \"engine\": \"XTTS_TTS\",\n",
    "            \"model_path\": \"models/tts/tts_models--multilingual--multi-dataset--xtts_v2\",\n",
    "            \"max_seq_len\": 128,\n",
    "        }\n",
    "tts = XTTS_TTS(config)\n",
    "response = tts.create(\n",
    "  voice=\"Vjollca Johnnie\",\n",
    "  input=\"The definition of insanity is doing the same thing over and over and expecting different results.\",\n",
    "  language=\"en\",\n",
    "  stream=True\n",
    ")\n",
    "from IPython.display import Audio\n",
    "audio_data = b''.join(chunk for chunk in response)\n",
    "Audio(audio_data, rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 14:11:44 INFO gai.gen.Gaigen:\u001b[32mGaigen: Loading generator xtts-2...\u001b[0m\n",
      "2024-06-12 14:11:44 INFO gai.gen.tts.TTS:\u001b[32mLoading TTS...\u001b[0m\n",
      "2024-06-12 14:11:44 INFO gai.gen.tts.TTS:\u001b[32mUsing tts model XTTS_TTS...\u001b[0m\n",
      "2024-06-12 14:11:44 INFO gai.gen.tts.XTTS_TTS:\u001b[32mLoading XTTS...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TTS...\n",
      "Loading XTTS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roylai/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-12 14:12:06,345] [INFO] [real_accelerator.py:161:get_accelerator] \u001b[32mSetting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "[2024-06-12 14:12:07,177] [INFO] [logging.py:96:log_dist] \u001b[32m[Rank -1] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown\u001b[0m\n",
      "[2024-06-12 14:12:07,179] [WARNING] [config_utils.py:69:_process_deprecated_field] \u001b[33mConfig parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\u001b[0m\n",
      "[2024-06-12 14:12:07,180] [WARNING] [config_utils.py:69:_process_deprecated_field] \u001b[33mConfig parameter mp_size is deprecated use tensor_parallel.tp_size instead\u001b[0m\n",
      "[2024-06-12 14:12:07,181] [INFO] [logging.py:96:log_dist] \u001b[32m[Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/roylai/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/roylai/.cache/torch_extensions/py310_cu121/transformer_inference/build.ninja...\n",
      "Building extension module transformer_inference...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load transformer_inference op: 0.08993363380432129 seconds\n",
      "[2024-06-12 14:12:08,102] [INFO] [logging.py:96:log_dist] \u001b[32m[Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module transformer_inference...\n",
      "2024-06-12 14:12:10 INFO gai.gen.tts.XTTS_TTS:\u001b[32mXTTS Loaded.\u001b[0m\n",
      "2024-06-12 14:12:10 INFO gai.gen.tts.XTTS_TTS:\u001b[32mXTTS generating...\u001b[0m\n",
      "2024-06-12 14:12:10 INFO gai.gen.tts.XTTS_TTS:\u001b[32mXTTS completed.\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n",
      "\u001b[1;32m      6\u001b[0m response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39mcreate(\n",
      "\u001b[1;32m      7\u001b[0m   voice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVjollca Johnnie\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m      8\u001b[0m   \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe definition of insanity is doing the same thing over and over and expecting different results.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m      9\u001b[0m   language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m     10\u001b[0m   stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Audio\n",
      "\u001b[0;32m---> 13\u001b[0m \u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda/envs/TTS/lib/python3.10/site-packages/IPython/lib/display.py:130\u001b[0m, in \u001b[0;36mAudio.__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n",
      "\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda/envs/TTS/lib/python3.10/site-packages/IPython/lib/display.py:152\u001b[0m, in \u001b[0;36mAudio._make_wav\u001b[0;34m(data, rate, normalize)\u001b[0m\n",
      "\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwave\u001b[39;00m\n",
      "\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 152\u001b[0m     scaled, nchan \u001b[38;5;241m=\u001b[39m \u001b[43mAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_normalize_with_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;32m    154\u001b[0m     scaled, nchan \u001b[38;5;241m=\u001b[39m Audio\u001b[38;5;241m.\u001b[39m_validate_and_normalize_without_numpy(data, normalize)\n",
      "\n",
      "File \u001b[0;32m~/miniconda/envs/TTS/lib/python3.10/site-packages/IPython/lib/display.py:172\u001b[0m, in \u001b[0;36mAudio._validate_and_normalize_with_numpy\u001b[0;34m(data, normalize)\u001b[0m\n",
      "\u001b[1;32m    168\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n",
      "\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_and_normalize_with_numpy\u001b[39m(data, normalize) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n",
      "\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;32m--> 172\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;32m    174\u001b[0m         nchan \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'generator'"
     ]
    }
   ],
   "source": [
    "## Gaigen\n",
    "from gai.gen import Gaigen\n",
    "gen = Gaigen.GetInstance(\"../../../gai-gen/gai.json\").load('xtts-2')\n",
    "response = gen.create(\n",
    "  voice=\"Vjollca Johnnie\",\n",
    "  input=\"The definition of insanity is doing the same thing over and over and expecting different results.\",\n",
    "  language=\"en\",\n",
    "  stream=True\n",
    ")\n",
    "from IPython.display import Audio\n",
    "Audio(response, rate=24000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
