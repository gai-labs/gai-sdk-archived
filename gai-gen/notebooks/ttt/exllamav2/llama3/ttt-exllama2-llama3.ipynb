{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "huggingface-cli download turboderp/Llama-3-8B-Instruct-exl2 \\\n",
    "    --revision 97d15f8fb9808afd51d7bccc3c3204ef3714f65a \\\n",
    "    --local-dir ~/gai/models/Llama-3-8B-Instruct-exl2 \\\n",
    "    --local-dir-use-symlinks False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roylai/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-12 21:55:09 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.load: Loading model from /home/roylai/gai/models/Meta-Llama-3-8B-Instruct-EXL2\u001b[0m\n",
      "2024-06-12 21:55:26 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.create: prompt=<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant that can generate short stories. You can generate a short story based on a prompt.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Tell me a one paragraph short story.<|eot_id|><|start_header_id|>assistant<|end_header_id|> schema=None tools=None prompt_format=llama3\u001b[0m\n",
      "2024-06-12 21:55:30 DEBUG gai.gen.ttt.ExLlamav2_TTT:\u001b[35mExLlama_TTT2._generating: content=As the last rays of sunlight faded from the sky, a lone figure emerged from the forest, her footsteps quiet on the dewy grass. Emilia had been searching for weeks for the ancient tree she had heard whispers about, said to hold the secrets of the forest within its gnarled branches. As she approached the towering trunk, a faint glow began to emanate from within, and she reached out a trembling hand to touch the bark. Suddenly, visions flooded her mind, of ancient rituals\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-824503ad-86eb-4c49-9d31-99d4d131d93d', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='As the last rays of sunlight faded from the sky, a lone figure emerged from the forest, her footsteps quiet on the dewy grass. Emilia had been searching for weeks for the ancient tree she had heard whispers about, said to hold the secrets of the forest within its gnarled branches. As she approached the towering trunk, a faint glow began to emanate from within, and she reached out a trembling hand to touch the bark. Suddenly, visions flooded her mind, of ancient rituals', role='assistant', function_call=None, tool_calls=None))], created=1718200530, model='ttt-exllama2-llama3', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=44, total_tokens=144))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gai.gen.ttt.ExLlamav2_TTT import ExLlamav2_TTT\n",
    "config = {\n",
    "            \"model_name\": \"ttt-exllama2-llama3\",\n",
    "            \"type\": \"ttt\",\n",
    "            \"engine\": \"ExLlamaV2_TTT\",\n",
    "            \"model_path\": \"models/Meta-Llama-3-8B-Instruct-EXL2\",\n",
    "            \"model_basename\": \"model\",\n",
    "            \"max_seq_len\": 8192,\n",
    "            \"prompt_format\": \"llama3\",\n",
    "            \"stop_conditions\": [\"<|eot_id|>\"],\n",
    "            \"hyperparameters\": {\n",
    "                \"temperature\": 0.85,\n",
    "                \"top_p\": 0.8,\n",
    "                \"top_k\": 50,\n",
    "                \"max_new_tokens\": 100,\n",
    "            },\n",
    "            \"no_flash_attn\":True,\n",
    "            \"seed\": None\n",
    "        }    \n",
    "gen = ExLlamav2_TTT(config)\n",
    "gen.load()\n",
    "response = gen.create(messages=[\n",
    "    {'role':'system','content':'You are a helpful assistant that can generate short stories. You can generate a short story based on a prompt.'},\n",
    "    {'role':'user','content':'Tell me a one paragraph short story.'},\n",
    "    {'role':'assistant','content':''}],\n",
    "    stream=False)\n",
    "gen.unload()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 21:55:46 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.load: Loading model from /home/roylai/gai/models/Meta-Llama-3-8B-Instruct-EXL2\u001b[0m\n",
      "2024-06-12 21:55:56 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.create: prompt=<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant that can generate short stories. You can generate a short story based on a prompt.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Tell me a one paragraph short story.<|eot_id|><|start_header_id|>assistant<|end_header_id|> schema=None tools=None prompt_format=llama3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the last rays of sunlight faded from the small town of Willow Creek, a lone figure emerged from the shadows. Lena, a former ballerina, had returned to her hometown after a devastating injury forced her to retire from the stage. With nothing but a worn-out ballet slipper and a handful of memories to her name, she began to dance again, her feet moving across the deserted main street as if guided by an unseen force. The wind carried the sweet scent of blooming cherry blossoms, and the rhythmic tap of her shoes seemed to awaken the very essence of the town, which had been sleeping for years. As the night deepened, the streets began to transform, and the once-forgotten buildings took on a new, ethereal glow, as if the magic of Lena's dance had awakened the very heart of Willow Creek."
     ]
    }
   ],
   "source": [
    "from gai.gen.ttt.ExLlamav2_TTT import ExLlamav2_TTT\n",
    "config = {\n",
    "            \"model_name\": \"ttt-exllama2-llama3\",\n",
    "            \"type\": \"ttt\",\n",
    "            \"engine\": \"ExLlamaV2_TTT\",\n",
    "            \"model_path\": \"models/Meta-Llama-3-8B-Instruct-EXL2\",\n",
    "            \"model_basename\": \"model\",\n",
    "            \"max_seq_len\": 8192,\n",
    "            \"prompt_format\": \"llama3\",\n",
    "            \"stop_conditions\": [\"<|eot_id|>\"],\n",
    "            \"hyperparameters\": {\n",
    "                \"temperature\": 0.85,\n",
    "                \"top_p\": 0.8,\n",
    "                \"top_k\": 50,\n",
    "                \"max_new_tokens\": 500,\n",
    "            },\n",
    "            \"no_flash_attn\":True,\n",
    "            \"seed\": None\n",
    "        } \n",
    "gen = ExLlamav2_TTT(config)\n",
    "gen.load()\n",
    "response = gen.create(messages=[\n",
    "    {'role':'system','content':'You are a helpful assistant that can generate short stories. You can generate a short story based on a prompt.'},\n",
    "    {'role':'user','content':'Tell me a one paragraph short story.'},\n",
    "    {'role':'assistant','content':''}],\n",
    "    stream=True)\n",
    "for chunk in response:\n",
    "    chunk=chunk.choices[0].delta.content\n",
    "    if chunk:\n",
    "        print(chunk, end='', flush=True)\n",
    "gen.unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## JSON Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 21:56:05 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.load: Loading model from /home/roylai/gai/models/Meta-Llama-3-8B-Instruct-EXL2\u001b[0m\n",
      "2024-06-12 21:56:14 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.create: prompt=<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You will respond to the user's message based only on the following JSON schema {'properties': {'title': {'title': 'Title', 'type': 'string'}, 'summary': {'title': 'Summary', 'type': 'string'}, 'author': {'title': 'Author', 'type': 'string'}, 'published_year': {'title': 'Published Year', 'type': 'integer'}}, 'required': ['title', 'summary', 'author', 'published_year'], 'title': 'Book', 'type': 'object'}. Begin your response with a curly bracket '{' and end it with a curly bracket '}'.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Foundation is a science fiction novel by American writer\n",
      "Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
      "expanded into the Foundation series). Foundation is a cycle of five\n",
      "interrelated short stories, first published as a single book by Gnome Press\n",
      "in 1951. Collectively they tell the early story of the Foundation,\n",
      "an institute founded by psychohistorian Hari Seldon to preserve the best\n",
      "of galactic civilization after the collapse of the Galactic Empire.\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|> schema={'properties': {'title': {'title': 'Title', 'type': 'string'}, 'summary': {'title': 'Summary', 'type': 'string'}, 'author': {'title': 'Author', 'type': 'string'}, 'published_year': {'title': 'Published Year', 'type': 'integer'}}, 'required': ['title', 'summary', 'author', 'published_year'], 'title': 'Book', 'type': 'object'} tools=None prompt_format=llama3\u001b[0m\n",
      "2024-06-12 21:56:17 DEBUG gai.gen.ttt.ExLlamav2_TTT:\u001b[35mExLlama_TTT2._generating: content={ \"title\": \"Foundation\", \"summary\": \"Science fiction novel by American writer Isaac Asimov. It is the first published in his Foundation Trilogy (later expanded into the Foundation series).\", \"author\": \"Isaac Asimov\", \"published_year\": 1951 }\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-d4eabdd2-f3f9-4657-8cbe-c598a04c359d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{ \"title\": \"Foundation\", \"summary\": \"Science fiction novel by American writer Isaac Asimov. It is the first published in his Foundation Trilogy (later expanded into the Foundation series).\", \"author\": \"Isaac Asimov\", \"published_year\": 1951 }', role='assistant', function_call=None, tool_calls=None))], created=1718200577, model='ttt-exllama2-llama3', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=58, prompt_tokens=242, total_tokens=300))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gai.gen.ttt.ExLlamav2_TTT import ExLlamav2_TTT\n",
    "config = {\n",
    "            \"model_name\": \"ttt-exllama2-llama3\",\n",
    "            \"type\": \"ttt\",\n",
    "            \"engine\": \"ExLlamaV2_TTT\",\n",
    "            \"model_path\": \"models/Meta-Llama-3-8B-Instruct-EXL2\",\n",
    "            \"model_basename\": \"model\",\n",
    "            \"max_seq_len\": 8192,\n",
    "            \"prompt_format\": \"llama3\",\n",
    "            \"stop_conditions\": [\"<|eot_id|>\"],\n",
    "            \"hyperparameters\": {\n",
    "                \"temperature\": 0.85,\n",
    "                \"top_p\": 0.8,\n",
    "                \"top_k\": 50,\n",
    "                \"max_new_tokens\": 400,\n",
    "            },\n",
    "            \"no_flash_attn\":True,\n",
    "            \"seed\": None\n",
    "        } \n",
    "gen = ExLlamav2_TTT(config)\n",
    "gen.load()\n",
    "\n",
    "# Define Schema\n",
    "from pydantic import BaseModel\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    author: str\n",
    "    published_year: int\n",
    "\n",
    "text = \"\"\"Foundation is a science fiction novel by American writer\n",
    "Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
    "expanded into the Foundation series). Foundation is a cycle of five\n",
    "interrelated short stories, first published as a single book by Gnome Press\n",
    "in 1951. Collectively they tell the early story of the Foundation,\n",
    "an institute founded by psychohistorian Hari Seldon to preserve the best\n",
    "of galactic civilization after the collapse of the Galactic Empire.\n",
    "\"\"\"\n",
    "response = gen.create(messages=[{'role':'user','content':text},{'role':'assistant','content':''}], \n",
    "    schema=Book.schema()\n",
    "    )\n",
    "gen.unload()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 21:56:22 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.load: Loading model from /home/roylai/gai/models/Meta-Llama-3-8B-Instruct-EXL2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<font color=\"yellow\">Model decided to use tool: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 21:56:31 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.create: prompt=<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "\n",
      "            1. Review the <tools> below and assess if any of them is suitable for responding to the user's message.\n",
      "\n",
      "                [{'type': 'function', 'function': {'name': 'google', 'description': \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\", 'parameters': {'type': 'object', 'properties': {'search_query': {'type': 'string', 'description': \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"}}, 'required': ['search_query']}}}]\n",
      "\n",
      "            2. If none of the tools are suitable, you can respond with a <text> response that looks like the following:\n",
      "                \n",
      "            {\n",
      "                \"function\": {\n",
      "                    \"name\": \"text\",\n",
      "                    \"arguments\": {\n",
      "                        \"text\": \"This is a text response.\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "            <|eot_id|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You will respond to the user's message based only on the following JSON schema {'type': 'object', 'properties': {'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'object'}}, 'required': ['name', 'arguments']}}, 'required': ['function']}. Begin your response with a curly bracket '{' and end it with a curly bracket '}'.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What time is it in Singapore right now?<|eot_id|><|start_header_id|>assistant<|end_header_id|> schema={'type': 'object', 'properties': {'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'object'}}, 'required': ['name', 'arguments']}}, 'required': ['function']} tools=[{'type': 'function', 'function': {'name': 'google', 'description': \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\", 'parameters': {'type': 'object', 'properties': {'search_query': {'type': 'string', 'description': \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"}}, 'required': ['search_query']}}}] prompt_format=llama3\u001b[0m\n",
      "2024-06-12 21:56:36 DEBUG gai.gen.ttt.ExLlamav2_TTT:\u001b[35mExLlama_TTT2._generating: function_name=google function_arguments={\"search_query\": \"current time in Singapore\"}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-b23daaa5-f2b7-417f-b354-ce807af6b78c', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_4bb569ea-472e-4a54-922b-566c9df499bb', function=Function(arguments='{\"search_query\": \"current time in Singapore\"}', name='google'), type='function')]))], created=1718200596, model='ttt-exllama2-llama3', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=35, prompt_tokens=450, total_tokens=485))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<font color=\"yellow\">Model decided not to use tool: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 21:56:36 INFO gai.gen.ttt.ExLlamav2_TTT:\u001b[32mExLlama_TTT2.create: prompt=<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "\n",
      "            1. Review the <tools> below and assess if any of them is suitable for responding to the user's message.\n",
      "\n",
      "                [{'type': 'function', 'function': {'name': 'google', 'description': \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\", 'parameters': {'type': 'object', 'properties': {'search_query': {'type': 'string', 'description': \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"}}, 'required': ['search_query']}}}]\n",
      "\n",
      "            2. If none of the tools are suitable, you can respond with a <text> response that looks like the following:\n",
      "                \n",
      "            {\n",
      "                \"function\": {\n",
      "                    \"name\": \"text\",\n",
      "                    \"arguments\": {\n",
      "                        \"text\": \"This is a text response.\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "            <|eot_id|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You will respond to the user's message based only on the following JSON schema {'type': 'object', 'properties': {'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'object'}}, 'required': ['name', 'arguments']}}, 'required': ['function']}. Begin your response with a curly bracket '{' and end it with a curly bracket '}'.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Tell me a one paragraph story.<|eot_id|><|start_header_id|>assistant<|end_header_id|> schema={'type': 'object', 'properties': {'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'object'}}, 'required': ['name', 'arguments']}}, 'required': ['function']} tools=[{'type': 'function', 'function': {'name': 'google', 'description': \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\", 'parameters': {'type': 'object', 'properties': {'search_query': {'type': 'string', 'description': \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"}}, 'required': ['search_query']}}}] prompt_format=llama3\u001b[0m\n",
      "2024-06-12 21:56:51 DEBUG gai.gen.ttt.ExLlamav2_TTT:\u001b[35mExLlama_TTT2._generating: function_text=Once upon a time, in a small village nestled in the rolling hills of the countryside, there lived a young girl named Sophie. She was a curious and adventurous soul, with a heart full of wonder and a mind full of questions. One day, while wandering through the woods, Sophie stumbled upon a hidden path she had never seen before. She decided to follow it, and it led her to a beautiful and mysterious clearing, where she discovered a hidden glade filled with wildflowers and a sparkling stream. As she sat down to rest and take in the beauty of her surroundings, Sophie realized that sometimes the most unexpected discoveries can lead to the most wonderful surprises.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-09ecf47b-c40f-40ca-920e-5524beb2772a', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Once upon a time, in a small village nestled in the rolling hills of the countryside, there lived a young girl named Sophie. She was a curious and adventurous soul, with a heart full of wonder and a mind full of questions. One day, while wandering through the woods, Sophie stumbled upon a hidden path she had never seen before. She decided to follow it, and it led her to a beautiful and mysterious clearing, where she discovered a hidden glade filled with wildflowers and a sparkling stream. As she sat down to rest and take in the beauty of her surroundings, Sophie realized that sometimes the most unexpected discoveries can lead to the most wonderful surprises.', role='assistant', function_call=None, tool_calls=None))], created=1718200611, model='ttt-exllama2-llama3', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=161, prompt_tokens=448, total_tokens=609))\n"
     ]
    }
   ],
   "source": [
    "from gai.gen.ttt.ExLlamav2_TTT import ExLlamav2_TTT\n",
    "config = {\n",
    "            \"model_name\": \"ttt-exllama2-llama3\",\n",
    "            \"type\": \"ttt\",\n",
    "            \"engine\": \"ExLlamaV2_TTT\",\n",
    "            \"model_path\": \"models/Meta-Llama-3-8B-Instruct-EXL2\",\n",
    "            \"model_basename\": \"model\",\n",
    "            \"max_seq_len\": 8192,\n",
    "            \"prompt_format\": \"llama3\",\n",
    "            \"stop_conditions\": [\"<|eot_id|>\"],\n",
    "            \"hyperparameters\": {\n",
    "                \"temperature\": 0.85,\n",
    "                \"top_p\": 0.8,\n",
    "                \"top_k\": 50,\n",
    "                \"max_new_tokens\": 100,\n",
    "            },\n",
    "            \"no_flash_attn\":True,\n",
    "            \"seed\": None\n",
    "        } \n",
    "gen = ExLlamav2_TTT(config)\n",
    "gen.load()\n",
    "\n",
    "from gai.common.notebook import highlight\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"google\",\n",
    "            \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "highlight(\"Model decided to use tool: \")\n",
    "user_prompt = \"What time is it in Singapore right now?\"\n",
    "response = gen.create(\n",
    "    messages=[\n",
    "        {'role':'user','content':user_prompt},\n",
    "        {'role':'assistant','content':''}],\n",
    "    tools=tools,\n",
    "    stream=False,\n",
    "    max_new_tokens=200)\n",
    "print(response)\n",
    "\n",
    "highlight(\"Model decided not to use tool: \")\n",
    "user_prompt = \"Tell me a one paragraph story.\"\n",
    "response = gen.create(\n",
    "    messages=[\n",
    "        {'role':'user','content':user_prompt},\n",
    "        {'role':'assistant','content':''}],\n",
    "    tools=tools,\n",
    "    stream=False,\n",
    "    max_new_tokens=200)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TTT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
