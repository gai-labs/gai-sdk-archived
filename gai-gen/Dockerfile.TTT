# syntax=docker/dockerfile:1.2

FROM torch2.2.0-cuda12.1-ubuntu22.04 as build

# Build Final ----------------------------------------------------------------------------------------

FROM pytorch/pytorch:2.2.0-cuda12.1-cudnn8-runtime AS base
ARG CATEGORY=ttt
ARG DEVICE=cuda
ENV DEBIAN_FRONTEND=noninteractive PIP_PREFER_BINARY=1

# Step 1: Install common dependencies

# Step 2: Install prebuilt wheels

## llama-cpp-python
WORKDIR /app/wheels
COPY --from=build /app/wheels/llama_cpp_python-*.whl /app/wheels/
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install /app/wheels/llama_cpp_python-*.whl

## exllamav2
WORKDIR /app/wheels
COPY --from=build /app/wheels/exllamav2-*.whl /app/wheels/
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install /app/wheels/exllamav2-*.whl

# Step 3: Copy Source Code
WORKDIR /app
COPY ./requirements_*.txt .
COPY ./setup.py ./gai.json ./
COPY ./gai ./gai

# Step 4: Install GAI
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -r requirements_${CATEGORY}.txt && \
    pip install -e .    
RUN ln -s /app/gai /src && \
    pip install debugpy

# Step 5: Create mount point for models
ENV MODEL_PATH="/app/models"
RUN echo '{"app_dir":"/app"}' > /root/.gairc    
WORKDIR /app/models

# Step 6: Start Server
WORKDIR /app/gai/api
ENV CATEGORY=${CATEGORY}
CMD ["bash","-c","python ${CATEGORY}_api.py"]



