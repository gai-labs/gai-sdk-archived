version: "3.8"

services:
    gai-ttt:
        build:
            context: .
            dockerfile: ./Dockerfile
            args:
                # For requirements_{category}.txt
                CATEGORY: "ttt"
        image: gai-ttt:latest
        container_name: gai-ttt
        environment:
            LOG_LEVEL: "DEBUG"
            TZ: "Asia/Singapore"
            SWAGGER_URL: "/doc"
            DEFAULT_GENERATOR: "mistral7b-exllama2"
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [gpu]
                          driver: nvidia
                          count: all
        ports:
            - "12031:12031"
        volumes:
            - ~/gai/models:/app/models
        networks:
            - gai-demo

    # gai-tts:
    #     build:
    #         context: .
    #         dockerfile: ./Dockerfile
    #         args:
    #             # For requirements_{category}.txt
    #             CATEGORY: "tts"
    #     image: gai-tts:latest
    #     container_name: gai-tts
    #     environment:
    #         LOG_LEVEL: "DEBUG"
    #         TZ: "Asia/Singapore"
    #         SWAGGER_URL: "/doc"
    #         DEFAULT_GENERATOR: "xtts-2"
    #     deploy:
    #         resources:
    #             reservations:
    #                 devices:
    #                     - capabilities: [gpu]
    #                       driver: nvidia
    #                       count: all
    #     ports:
    #         - "12032:12032"
    #     volumes:
    #         - ~/gai/models:/app/models
    #     networks:
    #         - gai-demo

    # gai-stt:
    #     build:
    #         context: .
    #         dockerfile: ./Dockerfile
    #         args:
    #             # For requirements_{category}.txt
    #             CATEGORY: "stt"
    #     image: gai-stt:latest
    #     container_name: gai-stt
    #     environment:
    #         LOG_LEVEL: "DEBUG"
    #         TZ: "Asia/Singapore"
    #         SWAGGER_URL: "/doc"
    #         DEFAULT_GENERATOR: "whisper-transformers"
    #     deploy:
    #         resources:
    #             reservations:
    #                 devices:
    #                     - capabilities: [gpu]
    #                       driver: nvidia
    #                       count: all
    #     ports:
    #         - "12033:12033"
    #     volumes:
    #         - ~/gai/models:/app/models
    #     networks:
    #         - gai-demo

    # gai-itt:
    #     build:
    #         context: .
    #         dockerfile: ./Dockerfile.ITT
    #         args:
    #             # For requirements_{category}.txt
    #             CATEGORY: "itt"
    #     image: gai-itt:latest
    #     container_name: gai-itt
    #     environment:
    #         LOG_LEVEL: "DEBUG"
    #         TZ: "Asia/Singapore"
    #         SWAGGER_URL: "/doc"
    #         DEFAULT_GENERATOR: "llava-transformers"
    #     deploy:
    #         resources:
    #             reservations:
    #                 devices:
    #                     - capabilities: [gpu]
    #                       driver: nvidia
    #                       count: all
    #     ports:
    #         - "12034:12034"
    #     volumes:
    #         - ~/gai/models:/app/models
    #     networks:
    #         - gai-demo

    # gai-tti:
    #     build:
    #         context: .
    #         dockerfile: ./Dockerfile.TTI
    #         args:
    #             # For requirements_{category}.txt
    #             CATEGORY: "tti"
    #     image: gai-tti:latest
    #     container_name: gai-tti
    #     environment:
    #         CLI_ARGS: "--listen --api --xformers --medvram"
    #     deploy:
    #         resources:
    #             reservations:
    #                 devices:
    #                     - capabilities: [gpu]
    #                       driver: nvidia
    #                       count: all
    #     ports:
    #         - "12035:12035"
    #     volumes:
    #         - ~/gai/models/Stable-diffusion:/stable-diffusion-webui/models/Stable-diffusion
    #         - ~/gai/models/VAE:/stable-diffusion-webui/models/VAE
    #     networks:
    #         - gai-demo

    gai-rag:
        build:
            context: ../gai-sdk/gai-gen
            dockerfile: Dockerfile
            args:
                # For requirements_{category}.txt
                CATEGORY: "rag"
        image: gai-rag:latest
        container_name: gai-rag
        environment:
            LOG_LEVEL: "DEBUG"
            TZ: "Asia/Singapore"
            SWAGGER_URL: "/doc"
            DEFAULT_GENERATOR: "instructor-rag"
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [gpu]
                          driver: nvidia
                          count: all
        ports:
            - "12036:12036"
        volumes:
            - ~/gai/models:/app/models
        networks:
            - gai-demo

networks:
    gai-demo:
        external: true
